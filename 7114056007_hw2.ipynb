{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9187ff0",
   "metadata": {},
   "source": [
    "# HW2 — Bike Sharing Demand Prediction (day.csv)\n",
    "\n",
    "**Follow CRISP-DM**: Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, Deployment.\n",
    "\n",
    "This notebook uses `day.csv` (Kaggle Bike Sharing). **Before running**, set `DATA_PATH` to the full path of your local `day.csv` file (example provided)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f783f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install required packages if needed (run once):\n",
    "```bash\n",
    "pip install -U scikit-learn pandas matplotlib nbformat scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0. Set dataset path ===\n",
    "# UPDATE this path to where your day.csv file is located on your machine or environment.\n",
    "DATA_PATH = '/root/.cache/kagglehub/datasets/gauravduttakiit/bike-sharing/versions/1/day.csv'\n",
    "\n",
    "# If your file is in the current working directory, you can use:\n",
    "# DATA_PATH = 'day.csv'\n",
    "\n",
    "print('Make sure DATA_PATH points to your day.csv file:')\n",
    "print(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d23f33",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "Predict daily bike rentals (`cnt`) to support operations and resource allocation.\n",
    "\n",
    "Deliverables required by assignment:\n",
    "- Use a Kaggle dataset (10–20 features) and cite the link.\n",
    "- Use Linear Regression; perform Feature Selection & Model Evaluation.\n",
    "- Include prediction plot with confidence/prediction interval.\n",
    "- Provide CRISP-DM documentation in report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482bc7d",
   "metadata": {},
   "source": [
    "## 2. Data Understanding\n",
    "Load dataset and inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print('Loaded dataset shape:', df.shape)\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    print('Error loading dataset. Please check DATA_PATH. Error:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a7f6c",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "- Drop leaking or unnecessary columns: `instant`, `dteday`, `casual`, `registered`.\n",
    "- Identify categorical vs numeric features.\n",
    "- Preprocessing: StandardScaler (numeric) + OneHotEncoder (categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Prepare X, y\n",
    "cols_to_drop = ['instant','dteday','casual','registered','cnt']\n",
    "X = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "y = df['cnt']\n",
    "\n",
    "categorical_features = [c for c in ['season','yr','mnth','holiday','weekday','workingday','weathersit'] if c in X.columns]\n",
    "numeric_features = [c for c in X.columns if c not in categorical_features]\n",
    "\n",
    "print('Numeric features:', numeric_features)\n",
    "print('Categorical features:', categorical_features)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(drop='first', sparse=False), categorical_features)\n",
    "])\n",
    "\n",
    "# Fit preprocessor to get transformed feature names\n",
    "X_trans = preprocessor.fit_transform(X)\n",
    "cat_encoder = preprocessor.named_transformers_['cat']\n",
    "cat_feature_names = list(cat_encoder.get_feature_names_out(categorical_features)) if categorical_features else []\n",
    "feature_names = numeric_features + cat_feature_names\n",
    "print('\\nTotal features after preprocessing:', len(feature_names))\n",
    "print(feature_names[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2f4ec",
   "metadata": {},
   "source": [
    "## 4. Feature Selection (RFE)\n",
    "We'll use RFE with LinearRegression to select top 10 features (or fewer if fewer exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Transform X to array for RFE\n",
    "X_array = preprocessor.transform(X)\n",
    "\n",
    "n_total = X_array.shape[1]\n",
    "n_select = min(10, n_total)\n",
    "\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=n_select)\n",
    "rfe.fit(X_array, y)\n",
    "\n",
    "# Selected feature names\n",
    "selected_mask = rfe.support_\n",
    "selected_features = [fname for fname, sel in zip(feature_names, selected_mask) if sel]\n",
    "\n",
    "import pandas as pd\n",
    "ranking_df = pd.DataFrame({'feature': feature_names, 'selected': selected_mask, 'ranking': rfe.ranking_})\n",
    "print('Selected features (RFE):', selected_features)\n",
    "display(ranking_df.sort_values(['selected','ranking']).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd005d2",
   "metadata": {},
   "source": [
    "## 5. Modeling\n",
    "Train a LinearRegression model using only the selected features. We'll split data into train/test (80/20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ab86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Build selector transformer\n",
    "class ColumnSelector:\n",
    "    def __init__(self, mask):\n",
    "        self.mask = np.array(mask)\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.mask]\n",
    "\n",
    "selector = ColumnSelector(selected_mask)\n",
    "\n",
    "final_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('selector', selector), ('lr', LinearRegression())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'RMSE: {rmse:.2f}')\n",
    "print(f'R2: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e14d5b1",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "- Metrics: RMSE, R²\n",
    "- Top 5 outliers (largest absolute residuals)\n",
    "- Plots: Actual vs Predicted + 95% prediction intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals and top outliers\n",
    "residuals = pd.Series(y_test - y_pred, index=y_test.index)\n",
    "abs_res = residuals.abs().sort_values(ascending=False)\n",
    "top5 = abs_res.head(5)\n",
    "print('Top 5 outliers (index : abs residual):')\n",
    "print(top5)\n",
    "\n",
    "# Prepare prediction intervals using linear model theory\n",
    "# Reconstruct design matrix for selected features\n",
    "X_train_trans = preprocessor.transform(X_train)\n",
    "X_train_sel = X_train_trans[:, selected_mask]\n",
    "X_train_design = np.hstack([np.ones((X_train_sel.shape[0],1)), X_train_sel])\n",
    "XtX_inv = np.linalg.inv(X_train_design.T.dot(X_train_design))\n",
    "\n",
    "X_test_trans = preprocessor.transform(X_test)\n",
    "X_test_sel = X_test_trans[:, selected_mask]\n",
    "X_test_design = np.hstack([np.ones((X_test_sel.shape[0],1)), X_test_sel])\n",
    "\n",
    "n_train = X_train_design.shape[0]\n",
    "p = X_train_design.shape[1]\n",
    "\n",
    "rss = np.sum((y_train - final_pipeline.predict(X_train))**2)\n",
    "sigma_hat = np.sqrt(rss / (n_train - p))\n",
    "\n",
    "from scipy.stats import t\n",
    "tval = t.ppf(0.975, df=n_train - p)\n",
    "se_pred = np.array([sigma_hat * np.sqrt(1.0 + x0.reshape(1,-1).dot(XtX_inv).dot(x0.reshape(-1,1))[0,0]) for x0 in X_test_design])\n",
    "lower = y_pred - tval * se_pred\n",
    "upper = y_pred + tval * se_pred\n",
    "\n",
    "print('\\nPrediction intervals computed (95%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf94a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Actual vs Predicted with prediction intervals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter Actual vs Predicted\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], linestyle='--')\n",
    "plt.xlabel('Actual count')\n",
    "plt.ylabel('Predicted count')\n",
    "plt.title('Actual vs Predicted (Linear Regression)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sorted plot with intervals\n",
    "order = np.argsort(y_test.values)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(len(y_test)), y_test.values[order], label='Actual')\n",
    "plt.plot(range(len(y_test)), y_pred[order], label='Predicted')\n",
    "plt.fill_between(range(len(y_test)), lower[order].flatten(), upper[order].flatten(), alpha=0.25)\n",
    "plt.legend()\n",
    "plt.title('Actual and Predicted with 95% Prediction Intervals (sorted by actual)')\n",
    "plt.xlabel('Sorted test samples')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efdbbca",
   "metadata": {},
   "source": [
    "## 7. Deployment\n",
    "- Save the model with `joblib.dump()` if needed.\n",
    "- The notebook and results (figures, CSVs) can be exported to include in the PDF report.\n",
    "\n",
    "---\n",
    "\n",
    "## Notes for the report (to include in PDF):\n",
    "- **Dataset source & link:** add Kaggle URL and dataset version used.\n",
    "- **GPT 輔助內容:** paste transcript exported via pdfCrowd.\n",
    "- **NotebookLM 摘要:** include a 100+ word summary of external research.\n",
    "\n",
    "---\n",
    "\n",
    "**End of notebook.**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
